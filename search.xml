<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Mineração de texto</title>
      <link href="/2020/05/17/mineracao-texto/"/>
      <url>/2020/05/17/mineracao-texto/</url>
      
        <content type="html"><![CDATA[<p>Atualmente, vivemos na era do Big Data, ou seja, estamos gerando dados a todo momento, porém, na maioria das vezes, são dados não estruturados, como notícias, e-mails e textos de forma geral. Mineração de textos ou do inglês <em>Text Mining</em>, tem como objetivo, encontrar termos relevantes e estabelecer relacionamento entre eles de acordo com a sua frequência e assim extrair informações de grandes volumes de textos.</p><h2 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h2><p><img src="/images/mineracao-texto/ciclo_mineracao.png" alt="Ciclo de mineração"></p><p>Agora, que sabemos que é possível obter informações, de grandes volumes de textos, vejamos como é o processo de obtenção dessas informações:</p><ul><li><p><strong>Começar com uma pergunta:</strong><br>Primeiramente, devemos ter um problema que queremos resolver, ou uma pergunta que desejamos responder, como, por exemplo: <em>Qual o pet mais querido no momento?</em></p></li><li><p><strong>Obter os dados:</strong><br>Agora, que temos um questionamento, precisamos conseguir os dados que o responda, sendo assim, utilizarei como fonte de dados, o que as pessoas estão conversando no Twitter.</p></li><li><p><strong>Limpar:</strong><br>E com os nossos dados em mãos, iremos realizar outra etapa do processo, que é a limpeza dos nossos dados, removendo caracteres especiais, como acentos, pontuações, tranformando todas as palavras em uma só estrutura, como, minúsculo e removeremos todas as <strong>stopwords</strong>, que são palavras irrelevantes para a pergunta que queremos responder.</p></li><li><p><strong>Analisar:</strong><br>Com os nossos dados prontos, iremos realizar uma das partes mais divertidas, que é analisar os nossos dados, onde poderemos aplicar diversas técnicas e verificar se com o dados que possuímos, responderemos à pergunta que nos motivou a analisar esses dados.</p></li><li><p><strong>Visualizar:</strong><br>Nessa etapa, poderemos visualizar o resultado da nossa análise e assim gerar diversas opções de gráficos, como, por exemplo, nuvem de palavras.</p></li><li><p><strong>Extrair conhecimento:</strong><br>E chegamos a última etapa, e se tudo estiver ocorrido bem, durante o processo de análise, teremos transformado os nossos dados em informação e agregando ao nosso entendimento prévio sobre o assunto, como resultado, gerado um conhecimento novo, sobre o fato que estávamos analisando.</p></li></ul><h2 id="Conceitos"><a href="#Conceitos" class="headerlink" title="Conceitos"></a>Conceitos</h2><p>Antes, de continuarmos, vamos conhecer alguns conceitos:</p><ul><li><strong>Corpus:</strong> Conjuntos de textos.</li><li><strong>Stopwords:</strong> Como comentado anteriormente, são palavras que não adicionam sentido ao texto, como palavras de ligação por exemplo e existem listas de stopwords para vários idiomas na internet.</li></ul><h2 id="Codigo-exemplo"><a href="#Codigo-exemplo" class="headerlink" title="Código exemplo"></a>Código exemplo</h2><p>Chegou o momento mais divertido onde criaremos um projeto básico de text mining, e para isso, utilizaremos a linguagem de programação <a href="https://cran.r-project.org/">R</a> e os seguintes pacotes:</p><ul><li><em>‘rtweet’</em> É um pacote, que permitirá que você se conecte ao Twitter, caso você tenha uma conta, onde você poderá realizar buscas, com no máximo 18 mil tweets.</li><li><em>‘tm’</em> O pacote tm de “Text Mining” é um pacote utilizado para trabalharmos com textos.</li><li><em>‘wordcloud’</em> É um pacote que nos permite visualizar de forma rápida, as palavras, utilizando como critério de tamanho, a frequência.</li><li><em>‘tydeverse’</em> É um pacote, que possui uma coleção de pacotes inclusos, para ajudar na manipulação dos dados.</li></ul><p>Primeiramente, vamos instalar os pacotes que serão necessários durante o projeto:</p><pre class=" language-R"><code class="language-R"># Instalando os pacotesinstall.packages("rtweet")install.packages("tm")install.packages("wordcloud")install.packages("tidyverse")</code></pre><p>E com os pacotes instalados, devemos carregar os mesmos e assim poderemos utilizar as funções desses pacotes.</p><pre class=" language-R"><code class="language-R"># Carregando os pacoteslibrary(tm)library(rtweet)library(wordcloud)library(tidyverse)</code></pre><p>Precisaremos de dados e vamos coletar esses dados utilizando a API do Twitter, usando a função de busca <em>‘search_tweets()’</em>, onde poderemos passar a <strong>#</strong> que queremos buscar ou termo, o número de tweets, onde o número máximo é 18 mil e se queremos ou não os retweets e a linguagem dos tweets, que no nosso caso será em inglês.</p><pre class=" language-R"><code class="language-R"># Buscando os tweets com #pets ou #petpets_tweets <- search_tweets(  "#pets OR #pet",  n = 18000,  include_rts = FALSE,  lang = "en")</code></pre><p>Visualizando a frequência de tweets utilizando #pets ou #pet, no intervalo de 1 hora:</p><pre class=" language-R"><code class="language-R"># Gerando um gráfico com a frequência dos tweets no intervalo de 1 horapets_tweets %>%   ts_plot("1 hours") +  ggplot2::theme_minimal() +  ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +  ggplot2::labs(    x = NULL,    y = NULL,    title = "Frequência de Pets no Twitter",    subtitle = "Tweets no intervalo de 1 hora",    caption = "\nSource: Dados coletados no Twitter REST API via rteet"  )</code></pre><p><img src="/images/mineracao-texto/frequencia.png" alt="Gráfico de frequência"></p><p>Vamos começar a mineração dos textos e para isso iremos pegar a (coluna) <em>text</em> e atribuir a uma variável.</p><pre class=" language-R"><code class="language-R"># Atribuindo os textos a uma variávelpet_text <- pets_tweets %>% pull(text)</code></pre><p>Tranformando os nossos textos em um corpus, para assim podermos realizar a limpeza utilizando a função <em>tm_map</em>, onde removeremos os caracteres especiais, transformaremos todas as letras para minúsculas, removeremos as pontuações e as stopwords em inglês.</p><pre class=" language-R"><code class="language-R"># Transformando os textos em um corpuspet_corpus <- VCorpus(VectorSource(pet_text))# Realizando a limpeza dos dados e removendo os termos 'pet' e 'pets', # pois é óbvio que essas palavras estão na nossa busca e serão as mais frequentespet_corpus <-   tm_map(    pet_corpus,    content_transformer(      function(x) iconv(x, from = 'UTF-8', to = 'ASCII//TRANSLIT')    )  ) %>%   tm_map(content_transformer(tolower)) %>%   tm_map(removePunctuation) %>%   tm_map(removeWords, stopwords("english")) %>%   tm_map(removeWords, c("pet", "pets"))</code></pre><p>Após, realizar a limpeza dos nossos textos, chegou o momento de visualizar o resultado em uma nuvem de palavras e iremos utilizar a função <em>brewer.pal</em>, para gerar as cores em hexadecimal, para assim, colorirmos a nossa nuvem.</p><pre class=" language-R"><code class="language-R"># Lista de cores em hexadecimalpaleta <- brewer.pal(8, "Dark2")# Criando uma nuvem de palavras, com no máximo 100 palavras# onde tenha se repetido ao menos 2 vezeswordcloud(  pet_corpus,  min.freq = 2,  max.words = 100,  color = paleta)</code></pre><p><img src="/images/mineracao-texto/nuvem1.png" alt="Nuvem de palavras"></p><p>Criando uma matriz de documentos-termos <em>(DocumentTermMatrix)</em>, onde posteriormente, removeremos os termos <em>menos</em> frequentes da matriz e somaremos os termos restantes para assim verificar quais são os termos mais utilizados.</p><pre class=" language-R"><code class="language-R"># Criando uma matriz de termospets_document <- DocumentTermMatrix(pet_corpus)# Removendo os termos menos frequentespets_doc <- removeSparseTerms(pets_document, 0.98)# Gerando uma matrix ordenada, com o termos mais frequentespets_freq <-   pets_doc %>%   as.matrix() %>%   colSums() %>%   sort(decreasing = T)</code></pre><p>Gerando um dataframe com os termos mais utilizados e visualizando em um gráfico.</p><pre class=" language-R"><code class="language-R"># Criando um dataframe com as palavras mais frequentesdf_pets <- data.frame(  word = names(pets_freq),  freq = pets_freq)# Gerando um gráfico da frequênciadf_pets %>%  subset(freq > 450) %>%   ggplot(aes(x = reorder(word, freq),             y = freq)) +  geom_bar(stat = "identity", fill='#0c6cad', color="#075284") +  theme(axis.text.x = element_text(angle = 45, hjus = 1)) +  ggtitle("Termos relacionados a Pet ou Pets mais frequentes no Twitter") +  labs(y = "Frequência", x = "Termos") +  coord_flip()</code></pre><p><img src="/images/mineracao-texto/termos_freq.png" alt="Termos mais frequentes"></p><p>E podemos visualizar o resultado em uma nuvem de palavras, porém utilizaremos outro pacote para gerar a nuvem que é o <em>wordcloud2</em>, pois ele gera uma nuvem de palavras mais bonita que o pacote que utilizamos até o momento,  mas antes, temos que instalar o pacote em nosso computador e utilizamos o comando abaixo para realizar a instalação.</p><pre class=" language-R"><code class="language-R"># Instalando o pacote 'devtools', caso não o tenha instalado em seu computadorif (!require(devtools)) install.packages("devtools")# Carregando o pacote 'devtools'library(devtools)# Instalando o pacote 'wordcloud2' via githubdevtools::install_github("lchiffon/wordcloud2", force = TRUE)</code></pre><p>E após, instalarmos, carregaremos o pacote <em>wordcloud2</em> e passaremos o nosso dataframe com os termos mais frequentes para a função <em>wordcloud2</em> e teremos como resultado o seguinte gráfico.</p><pre class=" language-R"><code class="language-R"># Carregando o pacote 'wordcloud2'library(wordcloud2)wordcloud2(data = df_pets)</code></pre><p><img src="/images/mineracao-texto/nuvem2.png" alt="Nuvem de palavras"></p><p>E podemos visualizar como os nossos termos estão relacionados, e para isso produziremos um dendrograma de agrupamento hierárquico, que é um diagrama de árvore.</p><pre class=" language-R"><code class="language-R"># Removendo os termos menos frequentespets_doc1 <- removeSparseTerms(pets_document, 0.95)# Dendogramadistancia <- dist(t(pets_doc1), method = "euclidian")dendograma <- hclust(d = distancia, method = "complete")plot(dendograma, habg = -1, main = "Dendograma Tweets Pets ou Pet",     xlab = "Distância",     ylab = "Altura")</code></pre><p><img src="/images/mineracao-texto/dendograma.png" alt="Dendograma"></p><p>E outra possibilidade que temos ao realizar mineração de textos é classificar os sentimentos dos termos utilizados, no nosso caso não fará muito sentido, pois é óbvio que o sentimento das pessoas em relação aos pets é um sentimento positivo, mas somente para exemplificar a posibilidade, vamos realizar essa análise e para isso utilizaremos o pacote <em>syuzhet</em>.</p><pre class=" language-R"><code class="language-R"># Instalando o pacote, caso não o tenha em seu PC.install.packages("syuzhet")# Carregando o pacotelibrary(syuzhet)</code></pre><p>Agora, que instalamos e carregamos o pacote, realizaremos a análise dos sentimentos dos nossos tweets e para tal análise utilizaremos a função <em>get_nrc_sentiment</em>, onde passaremos como parâmetro, os termos da nossa matriz de documentos-termos. E após, obtermos as emoções dos nossos termos, faremos o calculo da frequência dos sentimentos que utilizaram a #pet ou #pets.</p><pre class=" language-R"><code class="language-R"># Obtendo as emoções dos nossos termospets_sentimentos <- get_nrc_sentiment(  pets_doc$dimnames$Terms,  language = "english")# Calculando a frequência dos sentimentospets_sentimentos_freq <- pets_sentimentos %>%  colSums() %>%   sort(decreasing = T)</code></pre><p>Com a frequência dos nossos sentimentos calculada, poderemos visualizar o resultado, mas antes, iremos traduzir os sentimentos do inglês para o português e tranformar o resultado em um dataframe para posterirmente gerarmos o gráfico.</p><pre class=" language-R"><code class="language-R"># Criando um dataframe com os sentimentos traduzidos, que será utilizado como de-para. sentimetos_traducao <-   data.frame(    sentiment = c(      "positive",      "negative",      "trust",      "anticipation",      "fear",      "joy",      "sadness",      "surprise",      "anger",      "disgust"    ),    sentimentos = c(      "Positivo",      "Negativo",      "Confiança",      "Antecipação",      "Medo",      "Alegria",      "Tristeza",      "Surpresa",      "Raiva",      "Nojo"    )  )# Tranformando os resultados da frequência em um dataframe # e juntando ao dataframe de traduçãodf_sentimento <-   data.frame(    sentiment = names(pets_sentimentos_freq),    freq = pets_sentimentos_freq  ) %>%   left_join(sentimetos_traducao, by = "sentiment") %>%   dplyr::select(-sentiment) %>%   arrange(desc(freq))# Visualizando a frequência dos sentimentos em relação a #petsggplot(data = df_sentimento,       aes(x = reorder(sentimentos, -freq), y = freq)) +  geom_bar(aes(fill=sentimentos), stat = "identity") +  theme(legend.position = "none",        axis.text.x = element_text(angle = 45, hjus = 1)) +  xlab("Sentimentos") +  ylab("Frequência") +  ggtitle("Sentimentos das pessoas em relação aos Pets")</code></pre><p><img src="/images/mineracao-texto/sentimento.png" alt="Gráfico de sentimentos"></p><p>Então, é isso, espero que tenha gostado desse post e qual o termo que você utilizaria para buscar no Twitter?</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Data Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
            <tag> Data Science </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
